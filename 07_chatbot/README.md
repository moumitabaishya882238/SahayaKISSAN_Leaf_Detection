# ğŸŒ¾ Sahayakisan - AI-Powered Farmer Assistant Chatbot

An intelligent, voice-enabled agriculture chatbot built with React, FastAPI, and LangChain to help farmers with crop advice, pest management, market prices, and government schemes in multiple Indian languages.

## âœ¨ Features

### ğŸ¤ Voice & Multilingual Support

- **Voice Input**: Speak in Assamese, Hindi, or English
- **Speech Recognition**: Automatic speech-to-text using OpenAI Whisper
- **Language Detection**: Auto-detect language from voice input
- **Text-to-Speech Output**: Contextual voice responses in user's language
- **Recording Controls**: Visual mic feedback, stop speaking button

### ğŸ’¬ Smart Chat Interface

- **Session Management**: Create, switch, rename, and delete chat sessions
- **Persistent History**: All conversations saved and retrievable
- **Real-time Responses**: Streaming AI responses with loading indicators
- **Thinking Animation**: Visual feedback during AI processing
- **User & AI Avatars**: Distinctive visual identification

### ğŸ¨ User Experience

- **Modern Farmer Theme**: Clean, accessible UI with warm colors
- **Instagram-Inspired Gradients**: Vibrant visual design
- **Responsive Design**: Works on desktop and mobile
- **Dark Mode Ready**: Theme-based CSS variables for easy customization
- **Smooth Animations**: Fade-ins, slide-ups, pulse effects

### ğŸ¤– AI Capabilities

- **Contextual Conversations**: Multi-turn dialogue with context memory
- **Farmer-Focused Advice**: Crop guidance, pest management, fertilizer recommendations
- **Local Language Understanding**: Natural responses in Assamese, Hindi, English
- **Intent Recognition**: Understands navigation requests and common queries

## ğŸ› ï¸ Tech Stack

### Frontend

- **React 19** - UI framework with hooks
- **Vite 7.2** - Lightning-fast build tool
- **React Router DOM 7.13** - Client-side routing
- **Axios** - HTTP client for API calls
- **Web Audio API** - Voice recording
- **Web Speech Synthesis API** - Text-to-speech

### Backend

- **FastAPI** - Modern Python web framework
- **MongoDB** - NoSQL database for sessions and messages
- **LangChain** - LLM orchestration and memory
- **Ollama** - Local LLM deployment
- **OpenAI Whisper** - Speech-to-text transcription
- **FFmpeg** - Audio codec handling

## ğŸ“‹ Prerequisites

- **Python 3.10+**
- **Node.js 18+**
- **MongoDB** (local or cloud)
- **FFmpeg** (for audio processing)
- **Ollama** (for local LLM - optional but recommended)

## ğŸš€ Installation & Setup

### 1. Clone & Navigate

```bash
git clone <repository-url>
cd 07_chatbot
```

### 2. Backend Setup

```bash
cd backend

# Create Python environment
conda create -n chatbot python=3.10
conda activate chatbot

# Install dependencies
pip install -r requirements.txt

# Set up environment variables
# Create .env file with:
# MONGODB_URI=mongodb://localhost:27017
# OLLAMA_API_URL=http://localhost:11434

# Start FastAPI server
uvicorn app.main:app --reload --port 8000
```

### 3. Frontend Setup

```bash
cd ../frontend

# Install dependencies
npm install

# Start development server (auto-proxies to backend)
npm run dev
# Opens at http://localhost:5173
```

### 4. Install FFmpeg (Required for Voice)

**Windows (PowerShell):**

```powershell
winget install ffmpeg
```

**macOS:**

```bash
brew install ffmpeg
```

**Linux:**

```bash
sudo apt-get install ffmpeg
```

### 5. Set Up Ollama (Optional but Recommended)

```bash
# Download Ollama from https://ollama.ai
# Pull a model for local inference
ollama pull mistral
# Ollama runs on http://localhost:11434
```

## ğŸ“ Project Structure

```
07_chatbot/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py              # FastAPI setup, CORS, routers
â”‚   â”‚   â”œâ”€â”€ config.py            # Configuration
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py          # Chat endpoint, session management
â”‚   â”‚   â”‚   â”œâ”€â”€ speech.py        # STT transcription endpoint
â”‚   â”‚   â”‚   â””â”€â”€ auth.py          # Authentication (future)
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”œâ”€â”€ llm.py           # LLM setup with LangChain
â”‚   â”‚   â”‚   â””â”€â”€ memory.py        # Conversation memory
â”‚   â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”‚   â””â”€â”€ mongodb.py       # Database connection
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â””â”€â”€ helpers.py       # Utility functions
â”‚   â””â”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ Chat.jsx         # Main chat interface
â”‚   â”‚   â”‚   â””â”€â”€ Chat.css
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatInput.jsx    # Text & voice input
â”‚   â”‚   â”‚   â”œâ”€â”€ Message.jsx      # Message display with avatars
â”‚   â”‚   â”‚   â”œâ”€â”€ Sidebar.jsx      # Session manager
â”‚   â”‚   â”‚   â””â”€â”€ *.css            # Component styles
â”‚   â”‚   â”œâ”€â”€ context/
â”‚   â”‚   â”‚   â””â”€â”€ ChatContext.jsx  # Global state management
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ api.js           # API client
â”‚   â”‚   â”œâ”€â”€ App.jsx              # Root component
â”‚   â”‚   â””â”€â”€ main.jsx             # Entry point
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â””â”€â”€ chatbot.png          # AI avatar image
â”‚   â”œâ”€â”€ package.json             # Node dependencies
â”‚   â”œâ”€â”€ vite.config.js           # Vite configuration with proxy
â”‚   â””â”€â”€ index.html               # HTML template
â””â”€â”€ README.md
```

## ğŸ”Œ API Endpoints

### Chat Endpoints

- `POST /chat/` - Send message and get response
  - Payload: `{ "message": "...", "session_id": "...", "language": "hi|as|en" }`
  - Response: `{ "type": "TEXT", "reply": "...", "language": "..." }`

- `GET /chat/sessions` - List user sessions
- `GET /chat/messages/{session_id}` - Fetch session messages
- `POST /chat/session` - Create new session
- `DELETE /chat/session/{session_id}` - Delete session
- `PATCH /chat/session/{session_id}` - Rename session

### Speech Endpoints

- `POST /speech/transcribe` - Transcribe audio to text
  - Payload: `FormData { "file": AudioBlob }`
  - Response: `{ "text": "...", "language": "hi|as|en" }`

## ğŸ¯ Usage

1. **Start Chatting**
   - Type a question or click the mic to speak
   - AI responds with contextual farming advice

2. **Voice Interaction**
   - Click the ğŸ¤ button to record
   - Speak naturally in any supported language
   - Press â–  to stop, or wait for auto-stop
   - AI responds with voice + text

3. **Manage Sessions**
   - Click "New Chat" to start conversation
   - Rename sessions for easy tracking
   - Switch between sessions to view history
   - Delete sessions you no longer need

## ğŸ” Environment Variables

Create `.env` in the `backend/` directory:

```env
# Database
MONGODB_URI=mongodb://localhost:27017
DATABASE_NAME=sahayakisan

# LLM Configuration
OLLAMA_API_URL=http://localhost:11434
OLLAMA_MODEL=mistral

# API
CORS_ORIGINS=["http://localhost:5173"]
DEBUG=True
```

## ğŸ§ª Testing

### Test Chat Endpoint

```bash
curl -X POST http://localhost:8000/chat/ \
  -H "Content-Type: application/json" \
  -d '{"message": "How to grow tomatoes?", "session_id": "test-session"}'
```

### Test Transcription

```bash
curl -X POST http://localhost:8000/speech/transcribe \
  -F "file=@audio.wav"
```

## ğŸš¢ Deployment

### Backend (Heroku/Railway)

```bash
cd backend
# Use Procfile or configure platform settings
# Deploy with gunicorn: gunicorn app.main:app
```

### Frontend (Vercel/Netlify)

```bash
cd frontend
npm run build
# Deploy dist/ folder
```

## ğŸ›£ï¸ Roadmap

### Phase 1 (Current)

- âœ… Voice chat interface
- âœ… Multilingual support (Assamese, Hindi, English)
- âœ… Session management
- âœ… Modern UI with animations

### Phase 2

- ğŸ”² Disease detection from crop photos
- ğŸ”² Real-time weather integration
- ğŸ”² Market price tracker
- ğŸ”² Government schemes database

### Phase 3

- ğŸ”² User authentication & profiles
- ğŸ”² Offline support (PWA)
- ğŸ”² Advanced analytics dashboard
- ğŸ”² Expert consultation booking

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch: `git checkout -b feature/amazing-feature`
3. Commit changes: `git commit -m 'Add amazing feature'`
4. Push to branch: `git push origin feature/amazing-feature`
5. Open Pull Request
